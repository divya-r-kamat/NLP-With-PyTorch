# PyTorch Loss Functions

Broadly speaking, loss functions in PyTorch are divided into two main categories: regression losses and classification losses. 

- Regression loss functions are used when the model is predicting a continuous value, like the age of a person. 

- Classification loss functions are used when the model is predicting a discrete value, such as whether an email is spam or not. 

- Ranking loss functions are used when the model is predicting the relative distances between inputs, such as ranking products according to their relevance on an e-commerce search page. 

Following are the different types of loss functions in PyTorch:
  - Mean Absolute Error Loss
  - Mean Squared Error Loss
  - Negative Log-Likelihood Loss
  - Cross-Entropy Loss
  - Hinge Embedding Loss
  - Margin Ranking Loss
  - Triplet Margin Loss
  - Kullback-Leibler divergence

## Reference

- [PyTorch Loss Functions: The Ultimate Guide](https://neptune.ai/blog/pytorch-loss-functions)
- [CS230 Stanford Blog](https://cs230.stanford.edu/blog/pytorch/#loss-function)
- [PyTorch Implementation of Loss](https://analyticsindiamag.com/all-pytorch-loss-function/)

